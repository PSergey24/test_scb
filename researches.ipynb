{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b15a6d",
   "metadata": {},
   "source": [
    "    Интересно было поизучать какие-нибудь best practice для данных задач. Если найду что-нибудь интересной, буду добавлять сюда\n",
    "    \n",
    "    \n",
    "1) Подписан в телеграмме на некоторых известных ребят из ML, недавно находил ноутбук с конференции 2021 года для разных классических задач. Ребята для задачи toxic classification использовали эмбеддинги SBERT + простенькие модельки sklearn. Они говорят, что SBERT именно неплохо подходит для toxic classification задачи. \n",
    "\n",
    "При тюнинге BERT они используют metric learning подход. Metric learning это способ обучения нейросетей на основе какой-то функции близости (в данном случае triplet-loss), в случае с SBERT они заставляют модель сводить вектора BERT для фраз схожих по смыслу и разводить слова похожие по написанию но по смыслу различные.\n",
    "\n",
    "Отсюда SBERT неплохо справляется с семантическим поиском и дает неплохие вектора для задачи классификации токсичных сообщений, потому что тренировался на трпилетах токсичных фраз. \n",
    "\n",
    "А дальше просто получают вектора для фраз, которые нужно классифицировать и учат простой классификатор.\n",
    "\n",
    "Навряд ли именно SBERT подойдет для ваших данных из-за того, что он дообучался именно на токсичных комментариях. Но если Вам удастся полчить неплохие эмбеддинги для ваших данных тем же Бертом или другой моделькой. То идея вроде выглядит рабочей.\n",
    "\n",
    "https://colab.research.google.com/drive/1splCJMclOJlNTNi92R8TT5gla_8qtboX#scrollTo=JfylTqlT9f-l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e61f0",
   "metadata": {},
   "source": [
    "<img src='data/researches_01.png' width=640, heigth=480>\n",
    "<img src='data/researches_02.png' width=640, heigth=480>\n",
    "<img src='data/researches_03.png' width=640, heigth=480>\n",
    "<img src='data/researches_04.png' width=640, heigth=480>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f75543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78397b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb7ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
